{
  "title": "learn anything - mathematics - statistics - probability theory",
  "tag": "probabiliy theory",
  "nodes": [
    {
      "text": "probability theory",
      "url": "http://www.wikiwand.com/en/Probability_theory",
      "fx": -187.9376986228815,
      "fy": -225.10335010593224,
      "category": "wiki"
    },
    {
      "text": "basics",
      "note": "",
      "url": "",
      "fx": -134.6248087335215,
      "fy": -97.50442855461358
    },
    {
      "text": "probability distributions  ️",
      "url": "https://my.mindnode.com/zme7cJKFpqjzapGfVmvAQxKn8zE5xoXTyCfssHqp",
      "fx": -242.517070660405,
      "fy": 79.18478810639533,
      "category": "mindmap"
    },
    {
      "text": "prediction market",
      "url": "http://www.wikiwand.com/en/Prediction_market",
      "fx": -485.732203609409,
      "fy": 79.96989906272495,
      "category": "wiki"
    },
    {
      "text": "markov chains  ️",
      "note": "are stochastic processes that satisfy the Markov property (sometimes characterised as ‘memorylessness’)  a process satisfies the Markov property if one can make predictions for the future of the process based solely on its present state just as well as one could knowing the process’s full history, hence independently from such history (i.e. conditional on the present state of the system, its future and paste states are independent)  a Markov chain is a type of Markov process that has either discrete state space or discrete index set (often representing time), but the precise definition of a Markov chain varies",
      "url": "https://my.mindnode.com/1NpiefgrirDdunaD1stiWpyX3bcQbGMKP79hosmN",
      "fx": 51.847304043704526,
      "fy": 80.81032321877683,
      "category": "mindmap"
    },
    {
      "text": "conditional probability  ️",
      "url": "https://my.mindnode.com/UtaFiiR4M24aWKTfjoX6SDhfsgQ9BeopaGQd87xj",
      "fx": -756.2307586669922,
      "fy": 82.46343231201172,
      "category": "mindmap"
    },
    {
      "text": "expected value  ️",
      "url": "https://my.mindnode.com/BY6ZsiKtLZRTets2gBakqPVMW1DWfyMCuRzU7qLN",
      "fx": -968.3375946969668,
      "fy": 87.93832859841825,
      "category": "mindmap"
    }
  ],
  "subnodes": [
    {
      "text": "1. probability notes  ️",
      "url": "http://frnsys.com/ai_notes/foundations/probability.html",
      "fx": 47.37519126647851,
      "fy": -106.00442855461358,
      "category": "article",
      "color": "rgba(36, 170, 255, 1.0)",
      "parent": "basics"
    },
    {
      "text": "1. probability: theory and examples",
      "url": "http://www.goodreads.com/book/show/9632300-probability",
      "fx": 47.37519126647851,
      "fy": -66.00442855461358,
      "category": "non-free book",
      "color": "rgba(175, 54, 242, 1.0)",
      "parent": "basics"
    }
  ],
  "connections": [
    {
      "source": "probability theory",
      "target": "basics",
      "curve": {
        "x": -4.84355,
        "y": 62.5495
      }
    },
    {
      "source": "basics",
      "target": "markov chains  ️",
      "curve": {
        "x": 118.736,
        "y": 90.4074
      }
    },
    {
      "source": "basics",
      "target": "prediction market",
      "curve": {
        "x": -149.804,
        "y": 89.9871
      }
    },
    {
      "source": "basics",
      "target": "probability distributions  ️",
      "curve": {
        "x": -47.4461,
        "y": 88.3446
      }
    },
    {
      "source": "basics",
      "target": "conditional probability  ️",
      "curve": {
        "x": -311.698,
        "y": 64.9644
      }
    },
    {
      "source": "basics",
      "target": "expected value  ️",
      "curve": {
        "x": -471.261,
        "y": 40.5102
      }
    }
  ]
}